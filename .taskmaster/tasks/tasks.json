{
  "master": {
    "tasks": [
      {
        "id": 1,
        "title": "Initialize Next.js 15 Project with TypeScript",
        "description": "Set up a new Next.js 15 project using TypeScript, TailwindCSS, and shadcn/ui as the UI library.",
        "details": "Use the official Next.js 15 App Router template. Install TailwindCSS and shadcn/ui following their documentation. Initialize a GitHub private repository and configure GitHub Actions for CI. Prepare the project for deployment on Vercel.",
        "testStrategy": "Verify project builds and runs locally. Confirm Tailwind and shadcn/ui components render correctly. Ensure CI pipeline passes on push.",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 2,
        "title": "Configure Supabase Integration (Auth, Postgres, Storage)",
        "description": "Integrate Supabase for authentication, database, and storage. Enable passwordless email authentication and set up required tables.",
        "details": "Connect Supabase to the Next.js project. Enable Row-Level Security (RLS). Create tables: 'reports', 'scores', 'logs'. Configure Supabase Auth for passwordless email (Magic Link).",
        "testStrategy": "Test user signup/login via Magic Link. Validate RLS by attempting unauthorized access. Confirm data can be read/written to all tables.",
        "priority": "high",
        "dependencies": [
          1
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 3,
        "title": "Implement Passwordless Authentication Flow",
        "description": "Build frontend and backend logic for passwordless email authentication using Supabase Auth.",
        "details": "Create login/signup UI with shadcn/ui. Use Supabase client SDK to handle Magic Link requests and session management. Protect all app routes except login.",
        "testStrategy": "Attempt login/signup with valid and invalid emails. Confirm session persistence and route protection.",
        "priority": "high",
        "dependencies": [
          2
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 4,
        "title": "Design Database Schema for Reports, Scores, and Logs",
        "description": "Define and migrate the schema for 'reports', 'scores', and 'logs' tables in Supabase Postgres.",
        "details": "Design 'reports' to store generated report data, 'scores' for user evaluations (including per-criterion scores and comments), and 'logs' for observability (token usage, failures). Use SQL migrations or Supabase dashboard.",
        "testStrategy": "Insert, update, and query sample data for each table. Validate schema constraints and relationships.",
        "priority": "high",
        "dependencies": [
          2
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 5,
        "title": "Develop Multi-Agent Workflow with LangChain & LangGraph",
        "description": "Implement the autonomous agent loop using LangChain 0.2 and LangGraph, orchestrating Planner, Researcher, Ideator, Analyst, Critic, and Writer roles.",
        "details": "Set up LangGraph.js in the Next.js API layer. Implement each agent as a node: Planner (task breakdown), Researcher (Serper.dev + BS4 for web search/summary), Ideator (business model generation), Analyst (market sizing, risk), Critic (scoring/continue/stop), Writer (HTML report via Jinja2). Configure state transitions and stopping conditions as per PRD. Use environment variables for LLM model selection.",
        "testStrategy": "Run end-to-end agent loop with sample input. Validate correct state transitions, retries on LLM errors, and stopping conditions. Check output at each agent stage.",
        "priority": "high",
        "dependencies": [
          1,
          2,
          4
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 6,
        "title": "Integrate LLM Provider and Model Selection Logic",
        "description": "Connect to OpenAI GPT-4o (or other LLMs) via environment variables. Ensure critical agents use the correct model as specified in env config.",
        "details": "Use LangChain's ChatOpenAI wrapper. Read model names from .env (LLM_MODEL_CRITICAL for Analyst, Critic; default for others). Avoid hardcoding model names. Allow easy switching for development/testing.",
        "testStrategy": "Switch model names in .env and verify correct models are used for each agent. Test fallback to default if critical model is not set.",
        "priority": "medium",
        "dependencies": [
          5
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 7,
        "title": "Implement HTML Report Generation (A3 Landscape)",
        "description": "Generate a single-page HTML report per PRD spec, styled with TailwindCSS, using Jinja2 templating via LangChain.",
        "details": "Define Jinja2 template for all report sections (summary, business model, market size, synergy, risk, roadmap, scoring). Ensure layout fits A3 landscape and is responsive. Render in-browser using Next.js.",
        "testStrategy": "Generate reports with varied data. Visually inspect layout and content. Confirm all sections render as specified.",
        "priority": "high",
        "dependencies": [
          5
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 8,
        "title": "Build Report Generation and Viewing UI",
        "description": "Create frontend flows for theme input, report generation trigger, and report viewing. Display reports in a single-page HTML view.",
        "details": "Use shadcn/ui components for input forms and report display. Implement loading/progress indicators. Fetch and render generated reports from Supabase.",
        "testStrategy": "Submit theme, trigger generation, and view resulting report. Test with multiple reports and edge cases (long/short content).",
        "priority": "high",
        "dependencies": [
          3,
          7
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 9,
        "title": "Implement Scoring and Feedback Mechanism",
        "description": "Enable users to score reports on each evaluation criterion (1-5) and leave comments. Save to 'scores' table and update agent memory for future loops.",
        "details": "Add scoring UI to report view. On submit, store scores/comments in Supabase. Implement backend batch job to compute averages/variance and update LangGraph memory/prompts (no ML, just statistical updates).",
        "testStrategy": "Submit scores/comments, verify persistence. Check that new agent runs reflect updated prompt examples/statistics.",
        "priority": "medium",
        "dependencies": [
          4,
          8
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 10,
        "title": "Implement Report and Score History Listing",
        "description": "Provide a UI for users to view their past reports and associated scores/comments.",
        "details": "Create a history page listing all reports with summary info and links to full view. Display associated scores and comments. Use Supabase queries for data retrieval.",
        "testStrategy": "Generate multiple reports, score them, and verify all appear in history with correct data.",
        "priority": "medium",
        "dependencies": [
          8,
          9
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 11,
        "title": "Add Observability, Error Handling, and Cost Guardrails",
        "description": "Log token usage and failure counts to 'logs' table. Implement retry logic for LLM errors (up to 3 times) and enforce monthly API token cap.",
        "details": "Instrument agent workflow to log token counts and errors. On LLM failure, retry up to 3 times, then mark as 'failed'. Implement backend check to halt generation if token cap is exceeded.",
        "testStrategy": "Simulate LLM errors and high token usage. Verify retries, logging, and cap enforcement work as intended.",
        "priority": "medium",
        "dependencies": [
          5,
          4
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 12,
        "title": "Production Deployment and Security Hardening",
        "description": "Deploy to Vercel with SSL. Enable CSRF protection and verify Supabase RLS. Finalize environment variables and secrets management.",
        "details": "Configure Vercel deployment pipeline. Ensure all endpoints are protected against CSRF. Double-check Supabase RLS and environment variable usage. Document deployment steps.",
        "testStrategy": "Run security scans, attempt unauthorized access, and verify SSL/CSRF protections. Confirm production deployment is stable.",
        "priority": "high",
        "dependencies": [
          1,
          3,
          11
        ],
        "status": "pending",
        "subtasks": []
      }
    ],
    "metadata": {
      "created": "2025-07-15T14:25:14.652Z",
      "updated": "2025-07-15T14:25:14.652Z",
      "description": "Tasks for master context"
    }
  }
}